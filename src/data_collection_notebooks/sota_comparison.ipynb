{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bita54aa851efd74a40947ad31aa4b50f69",
   "display_name": "Python 3.6.9 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########### Prepare Data ###############\n",
    "########################################\n",
    "from modules.data_processor import generate_data\n",
    "\n",
    "path = '/home/Data/Timeseries/Classification/anomaly_new/anomaly_dataset.pickle'\n",
    "trainX, trainY, valX, valY, testX, testY, classes, seqlen, channel = generate_data(path, create_val=True, verbose=1)\n",
    "\n",
    "trainLen, valLen, testLen = trainX.shape[0], valX.shape[0], testX.shape[0]\n",
    "\n",
    "set_name = path.split(os.sep)[-2]\n",
    "model_path = os.path.join('../../models', set_name)\n",
    "img_path = os.path.join('../../images', set_name)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not modularized\n",
    "\n",
    "def validate_and_adjust_settings(zero, attach, notemp):\n",
    "    # 0 0 0 invalid\n",
    "    # 1 0 0 valid\n",
    "    # 0 1 0 valid\n",
    "    # 1 1 0 valid\n",
    "    # 0 0 1 invalid\n",
    "    # 1 0 1 valid\n",
    "    # 0 1 1 invalid\n",
    "    # 1 1 1 valid\n",
    "    if zero == 0 and attach == 0:\n",
    "        return 1, attach, notemp\n",
    "    if attach == 0 and notemp == 0:\n",
    "        return 1, attach, notemp\n",
    "    if notemp == 1:\n",
    "        return 1, attach, notemp\n",
    "    return zero, attach, notemp\n",
    "\n",
    "def define_setup(config, zero, attach, notemp):\n",
    "    s = 'strides_'\n",
    "    l = 'length_'\n",
    "    for c in config:\n",
    "        s += str(c[0]) + '-'\n",
    "        l += str(c[1]) + '-'\n",
    "    s = s[:-1] + '_' + l[:-1] +'_zero-'\n",
    "    s += '1' if zero else '0'\n",
    "    s += '_attach-'\n",
    "    s += '1' if attach else '0'\n",
    "    s += '_notemp-' \n",
    "    s += '1' if notemp else '0'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############# Patch Data ###############\n",
    "########################################\n",
    "from modules.data_generator import DataGenerator\n",
    "from modules.patch_generator import get_generator_id_list\n",
    "\n",
    "# [Stride, Length]\n",
    "config = [[5,5]]\n",
    "zero, attach, notemp = True, True, False\n",
    "zero, attach, notemp = validate_and_adjust_settings(zero, attach, notemp)\n",
    "\n",
    "params = {'dim': [seqlen, channel], 'batch_size': 1024, 'config': config,\n",
    "          'zero': zero, 'attach': attach, 'notemp': notemp, 'shuffle': False}\n",
    "\n",
    "setup = define_setup(config, zero, attach, notemp)\n",
    "setup_path = os.path.join(model_path, setup)\n",
    "if not os.path.exists(setup_path):\n",
    "    os.makedirs(setup_path)\n",
    "image_path = os.path.join(img_path, setup, 'sota')\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "\n",
    "# Generators\n",
    "trainIds = get_generator_id_list(trainLen, seqlen, config)\n",
    "train_generator = DataGenerator(trainIds, trainX, trainY, **params)\n",
    "valIds = get_generator_id_list(valLen, seqlen, config)\n",
    "val_generator = DataGenerator(valIds, valX, valY, **params)\n",
    "testIds = get_generator_id_list(testLen, seqlen, config)\n",
    "test_generator = DataGenerator(testIds, testX, testY, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Level 1 #############\n",
    "########################################\n",
    "from modules.model import create_model\n",
    "from modules.model_trainer import train_descriptive\n",
    "\n",
    "input_shape = trainX.shape[1:]\n",
    "if attach:\n",
    "    input_shape = list(input_shape)\n",
    "    input_shape[-1] +=1\n",
    "    input_shape = tuple(input_shape)\n",
    "patch_model_path = os.path.join(setup_path, 'patch_classifier.h5')\n",
    "\n",
    "patch_model = load_model(patch_model_path)\n",
    "\n",
    "softmax_trainXp = patch_model.predict(train_generator)[:len(trainIds)]\n",
    "softmax_valXp = patch_model.predict(val_generator)[:len(valIds)]\n",
    "softmax_testXp = patch_model.predict(test_generator)[:len(testIds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########## Prepare Level 2 #############\n",
    "########################################\n",
    "from modules.patch_generator import get_data_patch_stats, get_sample_id_list, compute_trivial_preds\n",
    "\n",
    "train_pps = get_data_patch_stats(trainLen, seqlen, config)[1]\n",
    "train_sidx = get_sample_id_list(trainLen, train_pps)\n",
    "val_pps = get_data_patch_stats(valLen, seqlen, config)[1]\n",
    "val_sidx = get_sample_id_list(valLen, val_pps)\n",
    "test_pps = get_data_patch_stats(testLen, seqlen, config)[1]\n",
    "test_sidx = get_sample_id_list(testLen, test_pps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Blackbox ############\n",
    "########################################\n",
    "from modules.model_trainer import train_blackbox\n",
    "from modules.data_generator import DataGenerator_simple\n",
    "\n",
    "# Generators\n",
    "params_simple = {'dim': [seqlen, channel], 'batch_size': 32, 'shuffle': False}\n",
    "train_generator_simple = DataGenerator_simple(np.arange(trainLen), trainX, trainY, **params_simple)\n",
    "val_generator_simple = DataGenerator_simple(np.arange(valLen), valX, valY, **params_simple)\n",
    "test_generator_simple = DataGenerator_simple(np.arange(testLen), testX, testY, **params_simple)\n",
    "\n",
    "blackbox_model_path = os.path.join(model_path, 'blackbox_classifier.h5')\n",
    "blackbox_model = load_model(blackbox_model_path)\n",
    "\n",
    "bm_train_pred = np.argmax(blackbox_model.predict(train_generator_simple), axis=-1)[:trainLen]\n",
    "bm_val_pred = np.argmax(blackbox_model.predict(val_generator_simple), axis=-1)[:valLen]\n",
    "bm_test_pred = np.argmax(blackbox_model.predict(test_generator_simple), axis=-1)[:testLen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "####### Parameter SOTA comparison ######\n",
    "########################################\n",
    "idx = 1\n",
    "save = True\n",
    "# lime\n",
    "num_samples = 5000\n",
    "num_features = 10\n",
    "num_slices = 10\n",
    "# shap\n",
    "num_random = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########### Plot Statistics ############\n",
    "########################################\n",
    "from modules.patch_generator import get_all_patch_params, get_data_patch_stats, get_all_patch, get_patch_params_list\n",
    "\n",
    "npc, pps = get_data_patch_stats(trainLen, seqlen, config)\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_dists = patch_model.predict(samples)\n",
    "param_list = get_patch_params_list(ids, trainLen, seqlen, config)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.plot(trainX[idx])\n",
    "for i, d in enumerate(patch_dists):\n",
    "    plt.axvspan(param_list[i,1] , param_list[i,2], color='C1' if d[1] > d[0] else 'C0', alpha=np.max(d)*0.5)\n",
    "\n",
    "if save:\n",
    "    name = 'patchx_' + str(idx)\n",
    "    plt.savefig(os.path.join(image_path, name + '.png'), dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Lime for time #############\n",
    "########################################\n",
    "from modules.lime_timeseries import LimeTimeSeriesExplainer\n",
    "\n",
    "explainer = LimeTimeSeriesExplainer(class_names=[str(i) for i in range(classes)])\n",
    "exp = explainer.explain_instance(trainX[idx], blackbox_model.predict, num_features=num_features, num_samples=num_samples, num_slices=num_slices, \n",
    "                                 replacement_method='total_mean', is_deep=True)\n",
    "#fig1 = exp.as_pyplot_figure()\n",
    "#plt.show()\n",
    "\n",
    "values_per_slice = np.ceil(len(trainX[idx]) / num_slices)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.plot(trainX[idx])\n",
    "\n",
    "for i in range(num_features):\n",
    "    feature, weight = exp.as_list()[i]\n",
    "    start = feature * values_per_slice\n",
    "    end = start + values_per_slice\n",
    "    color = 'C0' if weight < 0 else 'C1'\n",
    "    plt.axvspan(start , end, color=color, alpha=abs(weight)*0.5)\n",
    "\n",
    "if save:\n",
    "    name = 'lime_' + str(idx)\n",
    "    plt.savefig(os.path.join(image_path, name + '.png'), dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Shap for time #############\n",
    "########################################\n",
    "import shap\n",
    "\n",
    "random_ind = np.random.choice(trainX.shape[0], num_random, replace=False)\n",
    "e = shap.DeepExplainer((blackbox_model.layers[0].input, blackbox_model.layers[-2].output), trainX[random_ind])\n",
    "\n",
    "shap_val = e.shap_values(np.expand_dims(trainX[idx], axis=0))\n",
    "shap_abs = np.absolute(shap_val)\n",
    "sum_0 = np.sum(shap_abs,axis=0)[0]\n",
    "\n",
    "sum_0_red = np.sum(sum_0, axis=-1) \n",
    "sum_0_red /= np.max(sum_0_red)\n",
    "mi, ma = np.min(trainX[idx]), np.max(trainX[idx])\n",
    "\n",
    "pred = np.argmax(blackbox_model.predict(np.expand_dims(trainX[idx], axis=0)))\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.plot(trainX[idx])\n",
    "for i, d in enumerate(sum_0_red):\n",
    "    plt.axvspan(i-1 , i+1, color='C' + str(pred), alpha=d*0.5)\n",
    "\n",
    "if save:\n",
    "    name = 'shap_' + str(idx)\n",
    "    plt.savefig(os.path.join(image_path, name + '.png'), dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()"
   ]
  }
 ]
}