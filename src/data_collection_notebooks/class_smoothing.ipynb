{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "########### Prepare Data ###############\n",
    "########################################\n",
    "from modules.data_processor import generate_data\n",
    "\n",
    "root_path = '../../data/'\n",
    "datasets= ['character_trajectories/dataset_steps-20_timesteps-206.pickle', 'anomaly_new/anomaly_dataset.pickle', 'FordA/dataset_classes-2_timesteps-500.pickle', 'ElectricDevices/dataset_classes-7_timesteps-96.pickle', 'daily_and_sport_activites/dataset_classes-19_timesteps-60.pickle']\n",
    "path = os.path.join(root_path, datasets[1])\n",
    "trainX, trainY, valX, valY, testX, testY, classes, seqlen, channel = generate_data(path, create_val=True, verbose=1)\n",
    "\n",
    "trainLen, valLen, testLen = trainX.shape[0], valX.shape[0], testX.shape[0]\n",
    "\n",
    "set_name = path.split(os.sep)[-2]\n",
    "model_path = os.path.join('../../models', set_name)\n",
    "img_path = os.path.join('../../images', set_name)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not modularized\n",
    "\n",
    "def validate_and_adjust_settings(zero, attach, notemp):\n",
    "    # 0 0 0 invalid\n",
    "    # 1 0 0 valid\n",
    "    # 0 1 0 valid\n",
    "    # 1 1 0 valid\n",
    "    # 0 0 1 invalid\n",
    "    # 1 0 1 valid\n",
    "    # 0 1 1 invalid\n",
    "    # 1 1 1 valid\n",
    "    if zero == 0 and attach == 0:\n",
    "        return 1, attach, notemp\n",
    "    if attach == 0 and notemp == 0:\n",
    "        return 1, attach, notemp\n",
    "    if notemp == 1:\n",
    "        return 1, attach, notemp\n",
    "    return zero, attach, notemp\n",
    "\n",
    "def define_setup(config, zero, attach, notemp):\n",
    "    s = 'strides_'\n",
    "    l = 'length_'\n",
    "    for c in config:\n",
    "        s += str(c[0]) + '-'\n",
    "        l += str(c[1]) + '-'\n",
    "    s = s[:-1] + '_' + l[:-1] +'_zero-'\n",
    "    s += '1' if zero else '0'\n",
    "    s += '_attach-'\n",
    "    s += '1' if attach else '0'\n",
    "    s += '_notemp-' \n",
    "    s += '1' if notemp else '0'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############# Patch Data ###############\n",
    "########################################\n",
    "from modules.data_generator import DataGenerator\n",
    "from modules.patch_generator import get_generator_id_list\n",
    "\n",
    "# [Stride, Length]\n",
    "config = [[5,10]]\n",
    "zero, attach, notemp = True, True, False\n",
    "zero, attach, notemp = validate_and_adjust_settings(zero, attach, notemp)\n",
    "\n",
    "params = {'dim': [seqlen, channel], 'batch_size': 1024, 'config': config,\n",
    "          'zero': zero, 'attach': attach, 'notemp': notemp, 'shuffle': False}\n",
    "\n",
    "clf_type= 'svm'\n",
    "\n",
    "setup = define_setup(config, zero, attach, notemp)\n",
    "setup_path = os.path.join(model_path, setup)\n",
    "if not os.path.exists(setup_path):\n",
    "    os.makedirs(setup_path)\n",
    "image_path = os.path.join(img_path, setup, clf_type)\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "\n",
    "# Generators\n",
    "trainIds = get_generator_id_list(trainLen, seqlen, config)\n",
    "train_generator = DataGenerator(trainIds, trainX, trainY, **params)\n",
    "valIds = get_generator_id_list(valLen, seqlen, config)\n",
    "val_generator = DataGenerator(valIds, valX, valY, **params)\n",
    "testIds = get_generator_id_list(testLen, seqlen, config)\n",
    "test_generator = DataGenerator(testIds, testX, testY, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Level 1 #############\n",
    "########################################\n",
    "from modules.model import create_model\n",
    "from modules.model_trainer import train_descriptive\n",
    "\n",
    "input_shape = trainX.shape[1:]\n",
    "if attach:\n",
    "    input_shape = list(input_shape)\n",
    "    input_shape[-1] +=1\n",
    "    input_shape = tuple(input_shape)\n",
    "patch_model_path = os.path.join(setup_path, 'patch_classifier.h5')\n",
    "\n",
    "if os.path.exists(patch_model_path):\n",
    "    patch_model = tf.keras.models.load_model(patch_model_path)\n",
    "else:\n",
    "    patch_model = create_model(input_shape, classes)\n",
    "    patch_model = train_descriptive(patch_model_path, patch_model, trainIds, valIds, trainX, trainY, valX, valY, params, thresh=0.0, verbose=1, workers=1)\n",
    "\n",
    "softmax_trainXp = patch_model.predict(train_generator)[:len(trainIds)]\n",
    "softmax_valXp = patch_model.predict(val_generator)[:len(valIds)]\n",
    "softmax_testXp = patch_model.predict(test_generator)[:len(testIds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Level 2 #############\n",
    "########################################\n",
    "from modules.patch_generator import get_sample_id_list, create_histo_dataset, get_data_patch_stats\n",
    "from modules.model import create_clf\n",
    "from modules.model_trainer import train_clf\n",
    "\n",
    "train_pps = get_data_patch_stats(trainLen, seqlen, config)[1]\n",
    "train_sidx = get_sample_id_list(trainLen, train_pps)\n",
    "val_pps = get_data_patch_stats(valLen, seqlen, config)[1]\n",
    "val_sidx = get_sample_id_list(valLen, val_pps)\n",
    "test_pps = get_data_patch_stats(testLen, seqlen, config)[1]\n",
    "test_sidx = get_sample_id_list(testLen, test_pps)\n",
    "\n",
    "histo_trainX = create_histo_dataset(softmax_trainXp, train_sidx)\n",
    "histo_valX = create_histo_dataset(softmax_valXp, val_sidx)\n",
    "histo_testX = create_histo_dataset(softmax_testXp, test_sidx)\n",
    "\n",
    "clf_model_path = os.path.join(setup_path, clf_type + '_classifier.pickle')\n",
    "if os.path.exists(clf_model_path):\n",
    "    clf = load(clf_model_path)\n",
    "else:\n",
    "    clf = create_clf(clf_type)\n",
    "    clf = train_clf(clf_model_path, clf, histo_trainX, trainY, histo_valX, valY)\n",
    "\n",
    "clf_train_pred = clf.predict(histo_trainX)\n",
    "clf_val_pred = clf.predict(histo_valX)\n",
    "clf_test_pred = clf.predict(histo_testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "########### Plot Statistics ############\n",
    "########################################\n",
    "from modules.patch_generator import get_all_patch_params, get_data_patch_stats, get_all_patch, get_patch_params_list\n",
    "from modules.plot_processor import plot_heatmap, plot_class_means, plot_series_and_dist, plot_patch_and_dist, plot_class_overlay\n",
    "\n",
    "# patch + dist\n",
    "idx = 0\n",
    "show_patches = [0]\n",
    "\n",
    "npc, pps = get_data_patch_stats(trainLen, seqlen, config)\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_dists = patch_model.predict(samples)\n",
    "param_list = get_patch_params_list(ids, trainLen, seqlen, config)\n",
    "\n",
    "for i in show_patches:\n",
    "    plot_patch_and_dist(idx, trainX[idx], trainY[idx], np.argmax(patch_dists[i]), patch_dists[i], param_list[i], patch=i)#, save=image_path)\n",
    "\n",
    "# complete sample\n",
    "idx = 0\n",
    "\n",
    "npc, pps = get_data_patch_stats(trainLen, seqlen, config)\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_preds = patch_model.predict(samples)\n",
    "plot_series_and_dist(idx, trainX[idx], trainY[idx], clf_train_pred[idx], patch_preds)#, save=image_path)\n",
    "\n",
    "# class overlay\n",
    "idx = 0\n",
    "only_classes = [0]\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_dists = patch_model.predict(samples)\n",
    "param_list = get_patch_params_list(ids, trainLen, seqlen, config)\n",
    "plot_class_overlay(idx, trainX[idx], trainY[idx], clf_train_pred[idx], patch_dists, param_list, only_classes=only_classes)#, save=image_path)\n",
    "\n",
    "# class means\n",
    "#plot_heatmap(train_class_means)\n",
    "#plot_class_means(np.expand_dims(train_class_means[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not modularized\n",
    "\n",
    "def process_pipline(data, l1_model, l2_model, config, params, labels=None):\n",
    "    # data shapes\n",
    "    if len(data.shape) < 3:\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        if not labels is None:\n",
    "            labels= np.array([labels])\n",
    "    dataLen, seqLen, channels = data.shape\n",
    "    dataIds = get_generator_id_list(dataLen, seqLen, config)\n",
    "    # data generator\n",
    "    if labels is None:\n",
    "        data_generator = DataGenerator(dataIds, data, -np.ones(data.shape[0]), **params)\n",
    "    else:\n",
    "        data_generator = DataGenerator(dataIds, data, labels, **params)\n",
    "    # level 1\n",
    "    softmax_dataXp = l1_model.predict(data_generator)[:len(dataIds)]\n",
    "    # level 2\n",
    "    data_pps = get_data_patch_stats(dataLen, seqLen, config)[1]\n",
    "    data_sidx = get_sample_id_list(dataLen, data_pps)\n",
    "    histo_dataX = create_histo_dataset(softmax_dataXp, data_sidx)\n",
    "    clf_data_pred = l2_model.predict(histo_dataX)\n",
    "    # statistics\n",
    "    if not labels is None:\n",
    "        get_classification_report(labels, clf_data_pred, complete=True)\n",
    "    \n",
    "    return softmax_dataXp, histo_dataX, clf_data_pred\n",
    "\n",
    "def sample_modifier(src_data, target_data, src_ids, target_ids, src_channel=None, target_channel=None):\n",
    "    result = np.copy(target_data)\n",
    "    for i in range(len(src_ids)):\n",
    "        if src_channel is None:\n",
    "            result[target_ids[i][0]:target_ids[i][1]] = src_data[src_ids[i][0]:src_ids[i][1]]\n",
    "        else:\n",
    "            result[target_ids[i][0]:target_ids[i][1], target_channel[i]] = src_data[src_ids[i][0]:src_ids[i][1], src_channel[i]]\n",
    "    return result\n",
    "\n",
    "def compare_explanation(sample, patch_model, clf, config, params, blackbox_model, label):\n",
    "    soft_pred, histo_data, clf_pred = process_pipline(sample, patch_model, clf, config, params)\n",
    "    black_pred = blackbox_model.predict(np.expand_dims(sample, axis=0))\n",
    "    plot_series_and_dist(0, sample, label, clf_pred[0], soft_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not modularized \n",
    "\n",
    "idx = 1\n",
    "sample = trainX[idx]\n",
    "label = trainY[idx]\n",
    "\n",
    "steps = [1, 1.125, 1.25, 1.375, 1.5, 1.625, 1.75]\n",
    "\n",
    "series = []\n",
    "for i in steps:\n",
    "    m_sample = np.copy(sample)\n",
    "    m_sample[12,1] -= i\n",
    "    if m_sample[11,1] - m_sample[12,1] > 2:\n",
    "        label = 1\n",
    "    #compare_explanation(m_sample, patch_model, clf, config, params, blackbox_model, label)\n",
    "    soft_pred, histo_data, clf_pred = process_pipline(m_sample, patch_model, clf, config, params)\n",
    "    series.append([m_sample, label, soft_pred, clf_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not modularized \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "window = np.arange(5,21)\n",
    "zs = np.arange(len(series))\n",
    "ys = []\n",
    "for i in range(len(series)):\n",
    "    s = series[(len(series) -1) - i]\n",
    "    ts = s[0][window]\n",
    "    ys.append([[idx, ts[idx][1]] for idx in range(len(ts))])\n",
    "lines = LineCollection(ys, color=['C' + str(series[(len(series) -1) - i][1]) for i in range(len(series))])\n",
    "lines.set_alpha(0.7)\n",
    "ax.add_collection3d(lines, zs=zs, zdir='y')\n",
    "\n",
    "if 1:\n",
    "    patch2v = [[0,11], [5,16]]\n",
    "    patch2vid = [1,2]\n",
    "    for c in range(len(series)):\n",
    "        for i in range(len(patch2v)):\n",
    "            px = np.arange(patch2v[i][0], patch2v[i][1], 10)\n",
    "            s1 = (i+1) % 2\n",
    "            s2 = i % 2\n",
    "            py = np.array([(len(series) - 1) - c-0.4*s1, (len(series) - 1) - c+0.4*s2])\n",
    "            px, py = np.meshgrid(px, py)\n",
    "            pz = np.ones(np.ravel(px).shape) * -1.5\n",
    "            pz = pz.reshape(px.shape)\n",
    "            max_class = np.argmax(series[c][2][patch2vid[i]])\n",
    "            col = 'C' + str(max_class)\n",
    "            edge_col = 'C' + str(series[c][3][0])\n",
    "            ax.plot_surface(px, py, pz, color=col, edgecolor=edge_col, linewidth=3, alpha=np.max(series[c][2][patch2vid[i]]))\n",
    "\n",
    "\n",
    "ax.set_xlabel('Patch',  fontsize=16)\n",
    "ax.set_xticklabels(['', '1', '', '', '', '2', ''])\n",
    "ax.set_ylabel('Change',  fontsize=16)\n",
    "ax.set_zlabel('Softmax',  fontsize=16)\n",
    "\n",
    "fig.suptitle('Increased peak size over time',  fontsize=16)\n",
    "\n",
    "ax.set_xlabel('Timestep',  fontsize=16)\n",
    "ax.set_xlim3d(0,len(window))\n",
    "ax.set_xticks(np.arange(0, len(window)+1, 5))\n",
    "ax.set_xticklabels(window[::5])\n",
    "ax.set_ylabel('Change',  fontsize=16)\n",
    "ax.set_yticks(np.arange(len(series)))\n",
    "ax.set_yticklabels(np.arange(len(series))[::-1])\n",
    "ax.set_ylim3d(-.4, 6.4)\n",
    "ax.set_zlabel('Value',  fontsize=16)\n",
    "ax.set_zlim3d(-1.5, 2)\n",
    "\n",
    "fig.subplots_adjust(top=0.99)\n",
    "ax.view_init(elev=20, azim=30)#elev=10, \n",
    "#plt.savefig(os.path.join(image_path, 'Class_Smoothing'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not modularized \n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "window = np.array([1,2])\n",
    "for i in range(len(series)):\n",
    "    s = series[i]\n",
    "    xs = np.arange(len(s[2]))[window]\n",
    "    ys = np.max(s[2], axis=1)[window]\n",
    "    c = np.argmax(s[2][window], axis=1)\n",
    "    c = np.array(['C' + str(i) for i in c])\n",
    "\n",
    "    z = np.repeat(i, len(xs))\n",
    "\n",
    "    ax.bar(xs, ys, zs=z, zdir='y', color=c, edgecolor='black' , alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Patch',  fontsize=16)\n",
    "ax.set_xticklabels(['', '1', '', '', '', '2', ''])\n",
    "ax.set_ylabel('Change',  fontsize=16)\n",
    "ax.set_zlabel('Softmax',  fontsize=16)\n",
    "\n",
    "fig.suptitle('Patch label change over time',  fontsize=16)\n",
    "\n",
    "fig.subplots_adjust(top=0.99)\n",
    "ax.view_init(azim=45)#elev=10, \n",
    "#plt.savefig(os.path.join(image_path, 'Class_Smoothing_bars'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bita54aa851efd74a40947ad31aa4b50f69",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}