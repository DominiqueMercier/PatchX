{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "########### Prepare Data ###############\n",
    "########################################\n",
    "from data_processor import generate_data\n",
    "\n",
    "path = '../../data//character_trajectories/dataset_steps-20_timesteps-206.pickle'\n",
    "trainX, trainY, valX, valY, testX, testY, classes, seqlen, channel = generate_data(path, create_val=True, verbose=1)\n",
    "\n",
    "trainLen, valLen, testLen = trainX.shape[0], valX.shape[0], testX.shape[0]\n",
    "\n",
    "set_name = path.split(os.sep)[-2]\n",
    "model_path = os.path.join('../../models', set_name)\n",
    "img_path = os.path.join('../../images', set_name)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not modularized\n",
    "\n",
    "def validate_and_adjust_settings(zero, attach, notemp):\n",
    "    # 0 0 0 invalid\n",
    "    # 1 0 0 valid\n",
    "    # 0 1 0 valid\n",
    "    # 1 1 0 valid\n",
    "    # 0 0 1 invalid\n",
    "    # 1 0 1 valid\n",
    "    # 0 1 1 invalid\n",
    "    # 1 1 1 valid\n",
    "    if zero == 0 and attach == 0:\n",
    "        return 1, attach, notemp\n",
    "    if attach == 0 and notemp == 0:\n",
    "        return 1, attach, notemp\n",
    "    if notemp == 1:\n",
    "        return 1, attach, notemp\n",
    "    return zero, attach, notemp\n",
    "\n",
    "def define_setup(config, zero, attach, notemp):\n",
    "    s = 'strides_'\n",
    "    l = 'length_'\n",
    "    for c in config:\n",
    "        s += str(c[0]) + '-'\n",
    "        l += str(c[1]) + '-'\n",
    "    s = s[:-1] + '_' + l[:-1] +'_zero-'\n",
    "    s += '1' if zero else '0'\n",
    "    s += '_attach-'\n",
    "    s += '1' if attach else '0'\n",
    "    s += '_notemp-' \n",
    "    s += '1' if notemp else '0'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############# Patch Data ###############\n",
    "########################################\n",
    "from modules.data_generator import DataGenerator\n",
    "from modules.patch_generator_batch import get_generator_id_list\n",
    "\n",
    "# [Stride, Length]\n",
    "config = [[5,10]]\n",
    "zero, attach, notemp = True, True, False\n",
    "zero, attach, notemp = validate_and_adjust_settings(zero, attach, notemp)\n",
    "\n",
    "params = {'dim': [seqlen, channel], 'batch_size': 1024, 'config': config,\n",
    "          'zero': zero, 'attach': attach, 'notemp': notemp, 'shuffle': False}\n",
    "\n",
    "clf_type = 'svm'\n",
    "\n",
    "setup = define_setup(config, zero, attach, notemp)\n",
    "setup_path = os.path.join(model_path, setup)\n",
    "if not os.path.exists(setup_path):\n",
    "    os.makedirs(setup_path)\n",
    "image_path = os.path.join(img_path, setup, clf_type)\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "\n",
    "# Generators\n",
    "trainIds = get_generator_id_list(trainLen, seqlen, config)\n",
    "train_generator = DataGenerator(trainIds, trainX, trainY, **params)\n",
    "valIds = get_generator_id_list(valLen, seqlen, config)\n",
    "val_generator = DataGenerator(valIds, valX, valY, **params)\n",
    "testIds = get_generator_id_list(testLen, seqlen, config)\n",
    "test_generator = DataGenerator(testIds, testX, testY, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Level 1 #############\n",
    "########################################\n",
    "from modules.model import create_model\n",
    "from modules.model_trainer import train_descriptive\n",
    "\n",
    "input_shape = trainX.shape[1:]\n",
    "if attach:\n",
    "    input_shape = list(input_shape)\n",
    "    input_shape[-1] +=1\n",
    "    input_shape = tuple(input_shape)\n",
    "patch_model_path = os.path.join(setup_path, 'patch_classifier.h5')\n",
    "\n",
    "if os.path.exists(patch_model_path):\n",
    "    patch_model = tf.keras.models.load_model(patch_model_path)\n",
    "else:\n",
    "    patch_model = create_model(input_shape, classes)\n",
    "    patch_model = train_descriptive(patch_model_path, patch_model, trainIds, valIds, trainX, trainY, valX, valY, params, thresh=0.0, verbose=1, workers=1)\n",
    "\n",
    "softmax_trainXp = patch_model.predict(train_generator)[:len(trainIds)]\n",
    "softmax_valXp = patch_model.predict(val_generator)[:len(valIds)]\n",
    "softmax_testXp = patch_model.predict(test_generator)[:len(testIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Level 2 #############\n",
    "########################################\n",
    "from modules.patch_generator import get_sample_id_list, create_histo_dataset, get_data_patch_stats\n",
    "from modules.model import create_clf\n",
    "from modules.model_trainer import train_clf\n",
    "\n",
    "train_pps = get_data_patch_stats(trainLen, seqlen, config)[1]\n",
    "train_sidx = get_sample_id_list(trainLen, train_pps)\n",
    "val_pps = get_data_patch_stats(valLen, seqlen, config)[1]\n",
    "val_sidx = get_sample_id_list(valLen, val_pps)\n",
    "test_pps = get_data_patch_stats(testLen, seqlen, config)[1]\n",
    "test_sidx = get_sample_id_list(testLen, test_pps)\n",
    "\n",
    "histo_trainX = create_histo_dataset(softmax_trainXp, train_sidx)\n",
    "histo_valX = create_histo_dataset(softmax_valXp, val_sidx)\n",
    "histo_testX = create_histo_dataset(softmax_testXp, test_sidx)\n",
    "\n",
    "clf_model_path = os.path.join(setup_path, clf_type + '_classifier.pickle')\n",
    "if os.path.exists(clf_model_path):\n",
    "    clf = load(clf_model_path)\n",
    "else:\n",
    "    clf = create_clf(clf_type)\n",
    "    clf = train_clf(clf_model_path, clf, histo_trainX, trainY, histo_valX, valY)\n",
    "\n",
    "clf_train_pred = clf.predict(histo_trainX)\n",
    "clf_val_pred = clf.predict(histo_valX)\n",
    "clf_test_pred = clf.predict(histo_testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "######## Accuracy Statistics ###########\n",
    "########################################\n",
    "from modules.statistic_processor import get_classification_report, get_complete_evaluation, get_misclassifications, compute_class_mean\n",
    "from modules.file_writer import write_to_file\n",
    "\n",
    "get_classification_report(testY, clf_test_pred, complete=True)\n",
    "print('Interpretable')\n",
    "int_rep = get_complete_evaluation(trainY, valY, testY, clf_train_pred, clf_val_pred, clf_test_pred)\n",
    "\n",
    "train_mis = get_misclassifications(trainY, clf_train_pred)\n",
    "val_mis = get_misclassifications(valY, clf_val_pred)\n",
    "test_mis = get_misclassifications(testY, clf_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "########### Plot Statistics ############\n",
    "########################################\n",
    "from modules.patch_generator import get_all_patch_params, get_data_patch_stats, get_all_patch, get_patch_params_list\n",
    "from modules.plot_processor import plot_heatmap, plot_class_means, plot_series_and_dist, plot_patch_and_dist, plot_class_overlay\n",
    "\n",
    "# patch + dist\n",
    "idx = 789\n",
    "show_patches = [0]\n",
    "\n",
    "npc, pps = get_data_patch_stats(trainLen, seqlen, config)\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_dists = patch_model.predict(samples)\n",
    "param_list = get_patch_params_list(ids, trainLen, seqlen, config)\n",
    "\n",
    "for i in show_patches:\n",
    "    plot_patch_and_dist(idx, trainX[idx], trainY[idx], np.argmax(patch_dists[i]), patch_dists[i], param_list[i], patch=i)#, save=image_path)\n",
    "\n",
    "# complete sample\n",
    "idx = 789\n",
    "\n",
    "npc, pps = get_data_patch_stats(trainLen, seqlen, config)\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_preds = patch_model.predict(samples)\n",
    "plot_series_and_dist(idx, trainX[idx], trainY[idx], clf_train_pred[idx], patch_preds)#, save=image_path)\n",
    "\n",
    "# class overlay\n",
    "idx = 789\n",
    "only_classes = [4,10]\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_dists = patch_model.predict(samples)\n",
    "param_list = get_patch_params_list(ids, trainLen, seqlen, config)\n",
    "plot_class_overlay(idx, trainX[idx], trainY[idx], clf_train_pred[idx], patch_dists, param_list, only_classes=only_classes)#, save=image_path)\n",
    "\n",
    "# class means\n",
    "#plot_heatmap(train_class_means)\n",
    "#plot_class_means(np.expand_dims(train_class_means[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sort_by_class(dataY):\n",
    "    result = [np.where(dataY==i)[0] for i in np.unique(dataY)]\n",
    "    return result\n",
    "\n",
    "def plot_class_sample(data, dataSort, c, s):\n",
    "    plt.plot(data[dataSort[c][s]])\n",
    "    plt.show()\n",
    "    \n",
    "def plot_class_slice(data, dataSort):\n",
    "    n_rows = int(np.sqrt(len(dataSort)))\n",
    "    n_cols = int(np.ceil(len(dataSort) / n_rows))\n",
    "    g, b = plt.subplots(n_rows, n_cols, figsize=(20, 4*n_rows))\n",
    "    for i in range(len(dataSort)):\n",
    "        x = i % n_cols\n",
    "        y = i // n_cols\n",
    "        b[y][x].plot(data[dataSort[i][0]])\n",
    "        b[y][x].set_title('Class: %s' % (i))\n",
    "        \n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainSort = sort_by_class(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_class_sample(trainX, trainSort, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_class_slice(trainX, trainSort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ONLY FOR CHARACTER\n",
    "import scipy.io \n",
    "\n",
    "mat = scipy.io.loadmat('/home/Data/Timeseries/Classification/character_trajectories/mixoutALL_shifted.mat')\n",
    "chars = np.array([d[0] for d in np.squeeze(mat['consts'][0][0][3])])\n",
    "\n",
    "s = ''\n",
    "for i, c in enumerate(chars):\n",
    "    s += str(i) + ': ' + c + ' | '\n",
    "s = s[:-2]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_plot(xy_data):\n",
    "    grid_dir = int(np.ceil(np.max(np.sum(abs(xy_data), axis=0))))\n",
    "\n",
    "    dots = []\n",
    "    x_pos, y_pos, tip = 0, 0, 1\n",
    "    dots.append([x_pos, y_pos, tip])\n",
    "    for (x, y, t) in xy_data:\n",
    "        x_pos += x\n",
    "        y_pos += y\n",
    "        tip += t\n",
    "        dots.append([x_pos, y_pos, tip])\n",
    "\n",
    "    dots = np.transpose(np.array(dots), [1,0])\n",
    "    return dots\n",
    "\n",
    "def plot_dots(dots):\n",
    "    plt.scatter(dots[0], dots[1], c=dots[2], cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = 16\n",
    "s = 0\n",
    "\n",
    "xy_data = trainX[trainSort[c][s]]\n",
    "\n",
    "dots = convert_to_plot(xy_data)\n",
    "#plot_dots(dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window(org, syn):\n",
    "    ts = 0\n",
    "    diff = False\n",
    "    window = []\n",
    "    for i in range(org.shape[0]):\n",
    "        if np.any(org[i] != syn[i]):\n",
    "            if not diff:\n",
    "                diff = True\n",
    "                ts = i\n",
    "        elif diff:\n",
    "            window.append([ts, i-1])\n",
    "            diff = False\n",
    "    return np.array(window)\n",
    "\n",
    "def compare_idx(data, labels, idx, idx2, chars):\n",
    "    org = data[idx]\n",
    "    syn = data[idx2]\n",
    "\n",
    "    window = get_window(org, syn)\n",
    "\n",
    "    org_plot = convert_to_plot(org)\n",
    "    syn_plot = convert_to_plot(syn)\n",
    "    \n",
    "    labels = [chars[labels[i]] for i in [idx, idx2]]\n",
    "    return org, syn, org_plot, syn_plot, window, labels\n",
    "\n",
    "\n",
    "def plot_compare(org, syn, org_plot, syn_plot, window, labels, norm =False):\n",
    "    fig, ax = plt.subplots(2,2, figsize=(10,8))\n",
    "    fig.suptitle('GT 1: %s | GT 2: %s' % (labels[0], labels[1]))\n",
    "    ax[0,0].plot(org)\n",
    "    ax[0,1].plot(syn)\n",
    "    \n",
    "    if norm:\n",
    "        mi, ma = np.min([org_plot[1], syn_plot[1]]), np.max([org_plot[1], syn_plot[1]])\n",
    "        ax[1,0].set_ylim((mi,ma))\n",
    "        ax[1,1].set_ylim((mi,ma))\n",
    "    \n",
    "    ax[1,0].scatter(org_plot[0], org_plot[1], c=org_plot[2], cmap='Greys')\n",
    "    ax[1,1].scatter(syn_plot[0], syn_plot[1], c=syn_plot[2], cmap='Greys')\n",
    "    \n",
    "    for w in window:\n",
    "        ax[0,0].axvspan(w[0], w[1], alpha=0.5, color='yellow')\n",
    "        ax[0,1].axvspan(w[0], w[1], alpha=0.5, color='yellow')\n",
    "        \n",
    "        ax[1,0].scatter(org_plot[0][w[0]:w[1]], org_plot[1][w[0]:w[1]], c='yellow', marker='.')\n",
    "        ax[1,1].scatter(syn_plot[0][w[0]:w[1]], syn_plot[1][w[0]:w[1]], c='yellow', marker='.')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_highlight(sid, org, org_plot, window, label, label_names=None, norm =False, save=None):\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    fig.suptitle('Class distribtuion')\n",
    "\n",
    "    # sample\n",
    "    ax.set_title('Sample ID: ' + str(sid) + ' | Label: ' +\n",
    "                 str(label_names[label]))\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel('Value')\n",
    "        \n",
    "    if norm:\n",
    "        mi, ma = np.min(org_plot[1]), np.max(org_plot[1])\n",
    "        ax.set_ylim((mi,ma))\n",
    "        \n",
    "    ax.scatter(org_plot[0], org_plot[1], c=org_plot[2], cmap='Greys')\n",
    "    \n",
    "    for w in window:\n",
    "        ax.scatter(org_plot[0][w[0]:w[1]], org_plot[1][w[0]:w[1]], c='yellow', marker='.')\n",
    "\n",
    "    if not save is None:\n",
    "        fname = 'Class_overlay_char_' + str(sid)\n",
    "        if not only_classes is None:\n",
    "            fname += '_c-' + str(label) \n",
    "            plt.savefig(os.path.join(save, fname), dpi=300)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_1 = 1195#trainSort[0][0]\n",
    "sample_2 = trainSort[15][0]\n",
    "\n",
    "org, syn, org_plot, syn_plot, window, labels = compare_idx(trainX, trainY, sample_1, sample_2, chars)\n",
    "\n",
    "p1 = 5\n",
    "p2 = 19\n",
    "window = [[p1*5, p2*5+10]]\n",
    "\n",
    "#plot_compare(org, syn, org_plot, syn_plot, window, labels)\n",
    "plot_highlight(sample_2, syn, syn_plot, window, 15, chars, save=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def plot_description(sid, data, label, pred, patch_dists, param_list, only_classes=None, label_names=None, save=None):\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    fig.suptitle('Class distribtuion')\n",
    "\n",
    "    # sample\n",
    "    ax.set_title('Sample ID: ' + str(sid) + ' | Label: ' +\n",
    "                 str(label_names[label]) + ' | Pred: ' + str(label_names[pred]))\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_ylabel('Value')\n",
    "    dots = convert_to_plot(data)\n",
    "    plt.scatter(dots[0], dots[1], c=dots[2], cmap='Greys')\n",
    "\n",
    "    # dist\n",
    "    alpha = np.max(patch_dists, axis=1)\n",
    "    color = np.argmax(patch_dists, axis=1)\n",
    "\n",
    "    #color range\n",
    "    if patch_dists.shape[1] > 10:\n",
    "        cm = plt.get_cmap('tab20')\n",
    "        cNorm = matplotlib.colors.Normalize(\n",
    "            vmin=0, vmax=patch_dists.shape[1]-1)\n",
    "        scalarMap = matplotlib.cm.ScalarMappable(\n",
    "            norm=cNorm, cmap=cm)\n",
    "        color_val = [scalarMap.to_rgba(c) for c in np.arange(patch_dists.shape[1])]\n",
    "    else: \n",
    "        color_val = np.array(['C' + str(c) for c in np.arange(patch_dists.shape[1])])\n",
    "\n",
    "    for c in np.unique(color):\n",
    "        if not only_classes is None:\n",
    "            if not c in only_classes:\n",
    "                continue\n",
    "        dot_ids = np.where(color==c)[0]\n",
    "        dot_part = set()\n",
    "        for i in dot_ids:\n",
    "            dot_part.update(np.arange(param_list[i, 1], param_list[i, 2]))\n",
    "        dot_part = list(dot_part)\n",
    "        ax.scatter(dots[0][dot_part], dots[1][dot_part], color=color_val[c], label='Class: ' + str(label_names[c]))\n",
    "    \n",
    "        plt.legend()\n",
    "\n",
    "    if not save is None:\n",
    "        fname = 'Class_overlay_char_' + str(sid)\n",
    "        if not only_classes is None:\n",
    "            fname += '_c' \n",
    "            for c in only_classes:\n",
    "                fname += '-' + str(c)\n",
    "        plt.savefig(os.path.join(save, fname), dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "idx = 1195\n",
    "only_classes = [15]\n",
    "plot_description(idx, trainX[idx], trainY[idx], clf_train_pred[idx], patch_dists, param_list, only_classes=only_classes, label_names=chars, save=image_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bita54aa851efd74a40947ad31aa4b50f69",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}