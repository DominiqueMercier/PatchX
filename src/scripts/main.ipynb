{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "######### Tensorflow settings ##########\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "############ Append sys path ###########\n",
    "sys.path.append('../')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "########### Prepare Data ###############\n",
    "########################################\n",
    "from modules.data_processor import generate_data\n",
    "\n",
    "root_path = '../../data/'\n",
    "datasets= ['character_trajectories/dataset_steps-20_timesteps-206.pickle', 'anomaly_new/anomaly_dataset.pickle', 'FordA/dataset_classes-2_timesteps-500.pickle', 'ElectricDevices/dataset_classes-7_timesteps-96.pickle', 'daily_and_sport_activites/dataset_classes-19_timesteps-60.pickle']\n",
    "path = os.path.join(root_path, datasets[3])\n",
    "trainX, trainY, valX, valY, testX, testY, classes, seqlen, channel = generate_data(path, create_val=True, verbose=1)\n",
    "\n",
    "trainLen, valLen, testLen = trainX.shape[0], valX.shape[0], testX.shape[0]\n",
    "\n",
    "set_name = path.split(os.sep)[-2]\n",
    "model_path = os.path.join('../../models', set_name)\n",
    "img_path = os.path.join('../../images', set_name)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not modularized\n",
    "\n",
    "def validate_and_adjust_settings(zero, attach, notemp):\n",
    "    # 0 0 0 invalid\n",
    "    # 1 0 0 valid\n",
    "    # 0 1 0 valid\n",
    "    # 1 1 0 valid\n",
    "    # 0 0 1 invalid\n",
    "    # 1 0 1 valid\n",
    "    # 0 1 1 invalid\n",
    "    # 1 1 1 valid\n",
    "    if zero == 0 and attach == 0:\n",
    "        return 1, attach, notemp\n",
    "    if attach == 0 and notemp == 0:\n",
    "        return 1, attach, notemp\n",
    "    if notemp == 1:\n",
    "        return 1, attach, notemp\n",
    "    return zero, attach, notemp\n",
    "\n",
    "def define_setup(config, zero, attach, notemp):\n",
    "    s = 'strides_'\n",
    "    l = 'length_'\n",
    "    for c in config:\n",
    "        s += str(c[0]) + '-'\n",
    "        l += str(c[1]) + '-'\n",
    "    s = s[:-1] + '_' + l[:-1] +'_zero-'\n",
    "    s += '1' if zero else '0'\n",
    "    s += '_attach-'\n",
    "    s += '1' if attach else '0'\n",
    "    s += '_notemp-' \n",
    "    s += '1' if notemp else '0'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############# Patch Data ###############\n",
    "########################################\n",
    "from modules.data_generator import DataGenerator\n",
    "from modules.patch_generator import get_generator_id_list\n",
    "\n",
    "# [Stride, Length]\n",
    "config = [[5,10]]\n",
    "zero, attach, notemp = True, True, False\n",
    "zero, attach, notemp = validate_and_adjust_settings(zero, attach, notemp)\n",
    "\n",
    "params = {'dim': [seqlen, channel], 'batch_size': 1024, 'config': config,\n",
    "          'zero': zero, 'attach': attach, 'notemp': notemp, 'shuffle': False}\n",
    "\n",
    "# feature_type\n",
    "feature_mode = 'subset'\n",
    "feature_subset = 500\n",
    "\n",
    "# trivial mode\n",
    "triviral_mode='majority' if not 'anomaly' in path else 'occurance'\n",
    "\n",
    "# clf type\n",
    "clf_type = 'svm'\n",
    "use_dense = False\n",
    "\n",
    "setup = define_setup(config, zero, attach, notemp)\n",
    "setup_path = os.path.join(model_path, setup)\n",
    "if not os.path.exists(setup_path):\n",
    "    os.makedirs(setup_path)\n",
    "image_path = os.path.join(img_path, setup, clf_type)\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)\n",
    "\n",
    "# Generators\n",
    "trainIds = get_generator_id_list(trainLen, seqlen, config)\n",
    "train_generator = DataGenerator(trainIds, trainX, trainY, **params)\n",
    "valIds = get_generator_id_list(valLen, seqlen, config)\n",
    "val_generator = DataGenerator(valIds, valX, valY, **params)\n",
    "testIds = get_generator_id_list(testLen, seqlen, config)\n",
    "test_generator = DataGenerator(testIds, testX, testY, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Level 1 #############\n",
    "########################################\n",
    "from modules.model import create_model\n",
    "from modules.model_trainer import train_descriptive\n",
    "\n",
    "input_shape = trainX.shape[1:]\n",
    "if attach:\n",
    "    input_shape = list(input_shape)\n",
    "    input_shape[-1] +=1\n",
    "    input_shape = tuple(input_shape)\n",
    "patch_model_path = os.path.join(setup_path, 'patch_classifier.h5')\n",
    "\n",
    "if os.path.exists(patch_model_path):\n",
    "    patch_model = tf.keras.models.load_model(patch_model_path)\n",
    "else:\n",
    "    patch_model = create_model(input_shape, classes)\n",
    "    patch_model = train_descriptive(patch_model_path, patch_model, trainIds, valIds, trainX, trainY, valX, valY, params, thresh=0.0, verbose=1, workers=1)\n",
    "\n",
    "softmax_trainXp = patch_model.predict(train_generator)[:len(trainIds)]\n",
    "softmax_valXp = patch_model.predict(val_generator)[:len(valIds)]\n",
    "softmax_testXp = patch_model.predict(test_generator)[:len(testIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########## Prepare Level 2 #############\n",
    "########################################\n",
    "from modules.patch_generator import get_data_patch_stats, get_sample_id_list\n",
    "\n",
    "train_pps = get_data_patch_stats(trainLen, seqlen, config)[1]\n",
    "train_sidx = get_sample_id_list(trainLen, train_pps)\n",
    "val_pps = get_data_patch_stats(valLen, seqlen, config)[1]\n",
    "val_sidx = get_sample_id_list(valLen, val_pps)\n",
    "test_pps = get_data_patch_stats(testLen, seqlen, config)[1]\n",
    "test_sidx = get_sample_id_list(testLen, test_pps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########## Trivial Classifier ##########\n",
    "########################################\n",
    "from modules.patch_generator import compute_trivial_preds\n",
    "\n",
    "trivial_train_preds = compute_trivial_preds(softmax_trainXp, train_sidx, mode=triviral_mode)\n",
    "trivial_val_preds = compute_trivial_preds(softmax_valXp, val_sidx, mode=triviral_mode)\n",
    "trivial_test_preds = compute_trivial_preds(softmax_testXp, test_sidx, mode=triviral_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Level 2 #############\n",
    "########################################\n",
    "from modules.patch_generator import create_histo_dataset\n",
    "from modules.model import create_clf\n",
    "from modules.model_trainer import train_clf\n",
    "\n",
    "histo_trainX = create_histo_dataset(softmax_trainXp, train_sidx, full=True)\n",
    "histo_valX = create_histo_dataset(softmax_valXp, val_sidx, full=True)\n",
    "histo_testX = create_histo_dataset(softmax_testXp, test_sidx, full=True)\n",
    "\n",
    "clf_model_path = os.path.join(setup_path, clf_type + '_classifier.pickle')\n",
    "if os.path.exists(clf_model_path):\n",
    "    clf = load(clf_model_path)\n",
    "else:\n",
    "    clf = create_clf(clf_type)\n",
    "    clf = train_clf(clf_model_path, clf, histo_trainX, trainY, histo_valX, valY)\n",
    "\n",
    "clf_train_pred = clf.predict(histo_trainX)\n",
    "clf_val_pred = clf.predict(histo_valX)\n",
    "clf_test_pred = clf.predict(histo_testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Train Blackbox ############\n",
    "########################################\n",
    "from modules.model_trainer import train_blackbox\n",
    "from modules.data_generator import DataGenerator_sample\n",
    "\n",
    "# Generators\n",
    "params_simple = {'dim': [seqlen, channel], 'batch_size': 32, 'shuffle': False}\n",
    "train_generator_simple = DataGenerator_sample(np.arange(trainLen), trainX, trainY, **params_simple)\n",
    "val_generator_simple = DataGenerator_sample(np.arange(valLen), valX, valY, **params_simple)\n",
    "test_generator_simple = DataGenerator_sample(np.arange(testLen), testX, testY, **params_simple)\n",
    "\n",
    "blackbox_model_path = os.path.join(model_path, 'blackbox_classifier.h5')\n",
    "if os.path.exists(blackbox_model_path):\n",
    "    blackbox_model = load_model(blackbox_model_path)\n",
    "else:\n",
    "    blackbox_model = create_model(trainX.shape[1:], classes)\n",
    "    blackbox_model = train_blackbox(blackbox_model_path, blackbox_model, train_generator_simple, val_generator_simple, epochs=50, verbose=1, workers=1)\n",
    "\n",
    "bm_train_pred = np.argmax(blackbox_model.predict(train_generator_simple), axis=-1)[:trainLen]\n",
    "bm_val_pred = np.argmax(blackbox_model.predict(val_generator_simple), axis=-1)[:valLen]\n",
    "bm_test_pred = np.argmax(blackbox_model.predict(test_generator_simple), axis=-1)[:testLen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "############# Train SimpleClf ##########\n",
    "########################################\n",
    "from modules.model import create_clf\n",
    "from modules.model_trainer import train_clf, predict_clf\n",
    "\n",
    "simple_clf_model_path = os.path.join(model_path, 'simpleClf_' + clf_type + '_classifier.pickle')\n",
    "if os.path.exists(simple_clf_model_path):\n",
    "    simple_clf_model = load(simple_clf_model_path)\n",
    "else:\n",
    "    simple_clf_model = create_clf(clf_type)\n",
    "    simple_clf_model = train_clf(simple_clf_model_path, simple_clf_model, trainX, trainY, valX, valY)\n",
    "\n",
    "simple_clf_train_pred = predict_clf(simple_clf_model, trainX)\n",
    "simple_clf_val_pred = predict_clf(simple_clf_model, valX)\n",
    "simple_clf_test_pred = predict_clf(simple_clf_model, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "############ Feature Data ##############\n",
    "########################################\n",
    "from modules.feature_extractor import compute_relevant_subset_features, create_clf_features\n",
    "\n",
    "if feature_mode == 'subset':\n",
    "    feature_path = os.path.join(model_path, 'features_' + feature_mode + '_' + str(feature_subset) + '.pickle')\n",
    "else:\n",
    "    feature_path = os.path.join(model_path, 'features_' + feature_mode + '.pickle')\n",
    "\n",
    "if os.path.exists(feature_path):\n",
    "    with open(feature_path, 'rb') as f:\n",
    "        train_features, val_features, test_features = pickle.load(f)\n",
    "else:\n",
    "    if feature_mode == 'subset':\n",
    "        f_mode = 'given'\n",
    "        relevant_features = compute_relevant_subset_features(trainX, trainY, classes, num=feature_subset)\n",
    "    else:\n",
    "        f_mode = 'relevant'\n",
    "        relevant_features = None\n",
    "    \n",
    "    train_features, relevant_features = create_clf_features(trainX, trainY, pre_selected=relevant_features, mode=f_mode, return_names=True)\n",
    "    val_features = create_clf_features(valX, pre_selected=relevant_features, mode='given')\n",
    "    test_features = create_clf_features(testX, pre_selected=relevant_features, mode='given')\n",
    "\n",
    "    with open(feature_path, 'wb') as f:\n",
    "        pickle.dump([train_features, val_features, test_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "####### Train Feature SimpleClf ########\n",
    "########################################\n",
    "from modules.model import create_clf\n",
    "from modules.model_trainer import train_clf, predict_clf\n",
    "\n",
    "simple_clf_model_feature_path = os.path.join(model_path, 'simpleClf_' + clf_type + '_classifier_feature.pickle')\n",
    "if os.path.exists(simple_clf_model_feature_path):\n",
    "    simple_clf_feature_model = load(simple_clf_model_feature_path)\n",
    "else:\n",
    "    simple_clf_feature_model = create_clf(clf_type)\n",
    "    simple_clf_feature_model = train_clf(simple_clf_model_feature_path, simple_clf_model, train_features, trainY, val_features, valY)\n",
    "\n",
    "simple_clf_feature_train_pred = predict_clf(simple_clf_feature_model, train_features)\n",
    "simple_clf_feature_val_pred = predict_clf(simple_clf_feature_model, val_features)\n",
    "simple_clf_feature_test_pred = predict_clf(simple_clf_feature_model, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "######## Train Feature Blackbox ########\n",
    "########################################\n",
    "from modules.model import create_dense_model\n",
    "\n",
    "# Generators\n",
    "trainXf = np.expand_dims(train_features, axis=-1)\n",
    "valXf = np.expand_dims(val_features, axis=-1)\n",
    "testXf = np.expand_dims(test_features, axis=-1)\n",
    "\n",
    "params_feature_simple = {'dim': [train_features.shape[1], 1], 'batch_size': 32, 'shuffle': False}\n",
    "train_feature_generator_simple = DataGenerator_sample(np.arange(trainLen), trainXf, trainY, **params_feature_simple)\n",
    "val_feature_generator_simple = DataGenerator_sample(np.arange(valLen), valXf, valY, **params_feature_simple)\n",
    "test_feature_generator_simple = DataGenerator_sample(np.arange(testLen), testXf, testY, **params_feature_simple)\n",
    "\n",
    "blackbox_feature_model_path = os.path.join(model_path, 'blackbox_classifier_feature.h5' if not use_dense else 'blackbox_classifier_feature_dense.h5')\n",
    "if os.path.exists(blackbox_feature_model_path):\n",
    "    blackbox_feature_model = load_model(blackbox_feature_model_path)\n",
    "else:\n",
    "    if not use_dense:\n",
    "        blackbox_feature_model = create_model(trainXf.shape[1:], classes)\n",
    "    else:\n",
    "        blackbox_feature_model = create_dense_model(trainXf.shape[1:], classes)\n",
    "    blackbox_feature_model = train_blackbox(blackbox_feature_model_path, blackbox_feature_model, train_feature_generator_simple, val_feature_generator_simple, epochs=50, verbose=1, workers=1)\n",
    "\n",
    "bfm_train_pred = np.argmax(blackbox_feature_model.predict(train_feature_generator_simple), axis=-1)[:trainLen]\n",
    "bfm_val_pred = np.argmax(blackbox_feature_model.predict(val_feature_generator_simple), axis=-1)[:valLen]\n",
    "bfm_test_pred = np.argmax(blackbox_feature_model.predict(test_feature_generator_simple), axis=-1)[:testLen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "######## Accuracy Statistics ###########\n",
    "########################################\n",
    "from modules.statistic_processor import get_classification_report, get_complete_evaluation, get_misclassifications, compute_class_mean\n",
    "from modules.file_writer import write_to_file\n",
    "\n",
    "get_classification_report(testY, clf_test_pred, verbose=True)\n",
    "print('Interpretable')\n",
    "int_rep = get_complete_evaluation(trainY, valY, testY, clf_train_pred, clf_val_pred, clf_test_pred)\n",
    "\n",
    "print('Trivial')\n",
    "triv_rep = get_complete_evaluation(trainY, valY, testY, trivial_train_preds, trivial_val_preds, trivial_test_preds)\n",
    "\n",
    "print('Blackbox')\n",
    "black_rep = get_complete_evaluation(trainY, valY, testY, bm_train_pred, bm_val_pred, bm_test_pred)\n",
    "print('SimpleClf')\n",
    "simple_rep = get_complete_evaluation(trainY, valY, testY, simple_clf_train_pred, simple_clf_val_pred, simple_clf_test_pred)\n",
    "\n",
    "print('Feature Blackbox')\n",
    "black_feature_rep = get_complete_evaluation(trainY, valY, testY, bfm_train_pred, bfm_val_pred, bfm_test_pred)\n",
    "print('Feature SimpleClf')\n",
    "simple_feature_rep = get_complete_evaluation(trainY, valY, testY, simple_clf_feature_train_pred, simple_clf_feature_val_pred, simple_clf_feature_test_pred)\n",
    "            \n",
    "if not os.path.exists(os.path.join(setup_path, 'accuracy_report_' + clf_type + '.txt')):\n",
    "    write_to_file(os.path.join(setup_path, 'accuracy_report_' + clf_type + '.txt'), int_rep)\n",
    "\n",
    "if not os.path.exists(os.path.join(setup_path, 'accuracy_report_trivial.txt')):\n",
    "    write_to_file(os.path.join(setup_path, 'accuracy_report_trivial.txt'), triv_rep)\n",
    "\n",
    "if not os.path.exists(os.path.join(model_path, 'accuracy_report.txt')):\n",
    "    write_to_file(os.path.join(model_path, 'accuracy_report.txt'), black_rep)\n",
    "if not os.path.exists(os.path.join(model_path, 'accuracy_report_simpleClf_' + clf_type + '.txt')):\n",
    "    write_to_file(os.path.join(model_path, 'accuracy_report_simpleClf_' + clf_type + '.txt'), simple_rep)\n",
    "\n",
    "if not os.path.exists(os.path.join(model_path, 'accuracy_report_feature.txt' if not use_dense else 'accuracy_report_feature_dense.txt')):\n",
    "    write_to_file(os.path.join(model_path, 'accuracy_report_feature.txt' if not use_dense else 'accuracy_report_feature_dense.txt'), black_feature_rep)\n",
    "if not os.path.exists(os.path.join(model_path, 'accuracy_report_simpleClf_' + clf_type + '_feature.txt')):\n",
    "    write_to_file(os.path.join(model_path, 'accuracy_report_simpleClf_' + clf_type + '_feature.txt'), simple_feature_rep)\n",
    "\n",
    "# currently not in use\n",
    "train_mis = get_misclassifications(trainY, clf_train_pred)\n",
    "val_mis = get_misclassifications(valY, clf_val_pred)\n",
    "test_mis = get_misclassifications(testY, clf_test_pred)\n",
    "\n",
    "train_class_means = compute_class_mean(histo_trainX, trainY)\n",
    "val_class_means = compute_class_mean(histo_valX, valY)\n",
    "test_class_means = compute_class_mean(histo_testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "########### Plot Statistics ############\n",
    "########################################\n",
    "from modules.patch_generator import get_all_patch_params, get_data_patch_stats, get_all_patch, get_patch_params_list\n",
    "from modules.plot_processor import plot_heatmap, plot_class_means, plot_series_and_dist, plot_patch_and_dist, plot_class_overlay\n",
    "\n",
    "image_path_bak = image_path\n",
    "image_path = None\n",
    "\n",
    "# patch + dist\n",
    "idx = 0\n",
    "show_patches = [0]\n",
    "\n",
    "npc, pps = get_data_patch_stats(trainLen, seqlen, config)\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_dists = patch_model.predict(samples)\n",
    "param_list = get_patch_params_list(ids, trainLen, seqlen, config)\n",
    "\n",
    "for i in show_patches:\n",
    "    plot_patch_and_dist(idx, trainX[idx], trainY[idx], np.argmax(patch_dists[i]), patch_dists[i], param_list[i], patch=i, save=image_path)\n",
    "\n",
    "# complete sample\n",
    "idx = 0\n",
    "\n",
    "npc, pps = get_data_patch_stats(trainLen, seqlen, config)\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_preds = patch_model.predict(samples)\n",
    "plot_series_and_dist(idx, trainX[idx], trainY[idx], clf_train_pred[idx], patch_preds, save=image_path)\n",
    "\n",
    "# class overlay\n",
    "idx = 0\n",
    "only_classes = None#[0,1]\n",
    "ids = get_all_patch_params(idx, npc, pps)\n",
    "samples = get_all_patch(ids, trainX, trainLen, seqlen, config, zero, attach, notemp)\n",
    "\n",
    "patch_dists = patch_model.predict(samples)\n",
    "param_list = get_patch_params_list(ids, trainLen, seqlen, config)\n",
    "plot_class_overlay(idx, trainX[idx], trainY[idx], clf_train_pred[idx], patch_dists, param_list, only_classes=only_classes, save=image_path)\n",
    "\n",
    "# class means\n",
    "#plot_heatmap(train_class_means)\n",
    "#plot_class_means(np.expand_dims(train_class_means[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bita54aa851efd74a40947ad31aa4b50f69",
   "display_name": "Python 3.6.12 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}